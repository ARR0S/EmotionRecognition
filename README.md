# EmotionRecognition
Этот проект реализует распознавание эмоций на лице в реальном времени с помощью библиотеки `deepface` и OpenCV. Он захватывает видео с веб-камеры, обнаруживает лица и предсказывает эмоции, связанные с каждым лицом. Метки эмоций отображаются на кадрах в режиме реального времени.
Это, вероятно, самый короткий код для реализации мониторинга эмоций в реальном времени.

## Зависимости

- [deepface](https://github.com/serengil/deepface): Библиотека глубокого обучения для анализа лиц, которая предоставляет предварительно обученные модели для распознавания эмоций на лице. Она опирается на TensorFlow для базовых операций глубокого обучения.
- [OpenCV](https://opencv.org/): Библиотека компьютерного зрения с открытым исходным кодом, используемая для обработки изображений и видео.

## Использование
### Начальные шаги:
- Git clone this repository Run: `git clone https://github.com/ARR0S/EmotionRecognition.git`.
- Выполнить: `cd EmotionRecognition`.
1. Установите необходимые зависимости:
   - Вы можете использовать `pip install -r requirements.txt`.
   - Или вы можете установить зависимости по отдельности:
      - `pip install deepface`
      - `pip install tf_keras`
      - `pip install opencv-python`.

2. Загрузите XML-файл каскада Хаара для распознавания лиц:
   - Зайдите на [OpenCV GitHub repository](https://github.com/opencv/opencv/tree/master/data/haarcascades) и скачайте файл `haarcascade_frontalface_default.xml`.

3. Запустите код:
   - Выполните Python-скрипт.
   - Откроется веб-камера, и начнется распознавание эмоций на лице в реальном времени.
   - Метки эмоций будут отображаться в рамках вокруг обнаруженных лиц.

## Подход

1. Импортируйте необходимые библиотеки: `cv2` для захвата видео и обработки изображений и `deepface` для модели распознавания эмоций.

2. Загрузите XML-файл каскадного классификатора Хаара для распознавания лиц с помощью `cv2.CascadeClassifier()`.

3. Запустите захват видео с веб-камеры по умолчанию с помощью `cv2.VideoCapture()`.

4. Запустите непрерывный цикл для обработки каждого кадра захваченного видео.

5. Преобразуйте каждый кадр в оттенки серого с помощью `cv2.cvtColor()`.

6. Определите лица в полутоновом кадре с помощью `face_cascade.detectMultiScale()`.

7. Для каждого обнаруженного лица выделите область интереса (ROI).

8. Предварительно обработайте изображение лица для обнаружения эмоций с помощью встроенной функции предварительной обработки библиотеки `deepface`.

9. Сделайте предсказания для эмоций, используя предварительно обученную модель обнаружения эмоций, предоставленную библиотекой `deepface`.

10. Получение индекса предсказанной эмоции и сопоставление его с соответствующей меткой эмоции.

11. Нарисуйте прямоугольник вокруг обнаруженного лица и пометьте его предсказанной эмоцией с помощью `cv2.rectangle()` и `cv2.putText()`.

12. Отобразите полученный кадр с помеченной эмоцией с помощью `cv2.imshow()`.

13. Если нажата клавиша 'q', выйдите из цикла.

14. Освободите видеозахват и закройте все окна с помощью `cap.release()` и `cv2.destroyAllWindows()`.